{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import Libraries"
      ],
      "metadata": {
        "id": "wDJgvj7uUYDD"
      },
      "id": "wDJgvj7uUYDD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af20f53a",
      "metadata": {
        "id": "af20f53a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import random,shutil\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Dataset & Preprocessing"
      ],
      "metadata": {
        "id": "XWKJ9WgGUcD2"
      },
      "id": "XWKJ9WgGUcD2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5fb838c",
      "metadata": {
        "id": "d5fb838c"
      },
      "outputs": [],
      "source": [
        "dir= r'C:\\Users\\university\\Downloads\\1\\stble1\\dataset_new\\train'\n",
        "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' ):\n",
        "\n",
        "    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Split to Train & Test"
      ],
      "metadata": {
        "id": "LamxoXCdUf8F"
      },
      "id": "LamxoXCdUf8F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417a60f4",
      "metadata": {
        "id": "417a60f4",
        "outputId": "788944ce-3e0e-4dff-b409-042b7a64fd55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1234 images belonging to 2 classes.\n",
            "Found 218 images belonging to 2 classes.\n",
            "38 6\n"
          ]
        }
      ],
      "source": [
        "BS= 32\n",
        "TS=(24,24)\n",
        "train_batch= generator(r'C:\\Users\\university\\Downloads\\1\\stble1\\dataset_new\\train',shuffle=True, batch_size=BS,target_size=TS)\n",
        "valid_batch= generator(r'C:\\Users\\university\\Downloads\\1\\stble1\\dataset_new\\test',shuffle=True, batch_size=BS,target_size=TS)\n",
        "SPE= len(train_batch.classes)//BS\n",
        "VS = len(valid_batch.classes)//BS\n",
        "print(SPE,VS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the Model"
      ],
      "metadata": {
        "id": "Slz01pobUxDF"
      },
      "id": "Slz01pobUxDF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2a060b",
      "metadata": {
        "id": "4c2a060b"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
        "    MaxPooling2D(pool_size=(1,1)),\n",
        "    Conv2D(32,(3,3),activation='relu'),\n",
        "    MaxPooling2D(pool_size=(1,1)),\n",
        "#32 convolution filters used each of size 3x3\n",
        "#again\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(1,1)),\n",
        "\n",
        "#64 convolution filters used each of size 3x3\n",
        "#choose the best features via pooling\n",
        "    \n",
        "#randomly turn neurons on and off to improve convergence\n",
        "    Dropout(0.25),\n",
        "#flatten since too many dimensions, we only want a classification output\n",
        "    Flatten(),\n",
        "#fully connected to get all relevant data\n",
        "    Dense(128, activation='relu'),\n",
        "#one more dropout for convergence' sake :) \n",
        "    Dropout(0.5),\n",
        "#output a softmax to squash the matrix into output probabilities\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visulizing Architecture of Model"
      ],
      "metadata": {
        "id": "RDdFRociVEU1"
      },
      "id": "RDdFRociVEU1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda9d0a2",
      "metadata": {
        "id": "fda9d0a2"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training"
      ],
      "metadata": {
        "id": "zOGOWVpFU8iO"
      },
      "id": "zOGOWVpFU8iO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd1021b",
      "metadata": {
        "id": "bbd1021b"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
        "\n",
        "model.save('models/stb1test.h5', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808d45e7",
      "metadata": {
        "id": "808d45e7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}